# Dataproc: Qwik Start - Command Line

## Theory
Cloud Dataproc is a fast, easy-to-use, fully-managed cloud service for running Apache Spark and Apache Hadoop clusters in a simpler, more cost-efficient way. Operations that used to take hours or days take seconds or minutes instead. Create Cloud Dataproc clusters quickly and resize them at any time, so you don't have to worry about your data pipelines outgrowing your clusters.

## What we did

In this lab, we learnt:-

1. Create a cluster
2. Submit a job
3. Update a cluster

## Tasks Performed
1. Create a cluster
2. Submit a job
3. Update a cluster

## New Terms

1. To submit a job in the command line:
```cmd
gcloud dataproc jobs submit spark --cluster example-cluster \
  --class org.apache.spark.examples.SparkPi \
  --jars file:///usr/lib/spark/examples/jars/spark-examples.jar -- 1000 
```
This command specifies:
1. That you want to run a spark job on the example-cluster cluster
2. The class containing the main method for the job's pi-calculating application
3. The location of the jar file containing your job's code
4. The parameters you want to pass to the jobâ€”in this case, the number of tasks, which is 1000

2. To change the number of workers in the cluster, to lets say, six
```cmd 
gcloud dataproc clusters update example-cluster --num-workers 6
```