# Entity and Sentiment Analysis with the Natural Language API

## Theory

The **Cloud Natural Language API** lets you extract entities from text, perform sentiment and syntactic analysis, and classify text into categories.

The Natural Language API also supports sending files stored in Cloud Storage for text processing.

For each entity in the response, you get the entity type, the associated Wikipedia URL if there is one, the salience, and the indices of where this entity appeared in the text. Salience is a number in the [0,1] range that refers to the centrality of the entity to the text as a whole.

The Natural Language API can also recognize the same entity mentioned in different ways.

**Sentiment analysis** is the process of analyzing digital text to determine if the emotional tone of the message is positive, negative, or neutral.

In addition to providing sentiment details on the entire text document, the Natural Language API can also break down sentiment by the entities in the text. Use this sentence as an example:

*I liked the sushi but the service was terrible.*

In this case, getting a sentiment score for the entire sentence as you did above might not be so useful. If this was a restaurant review and there were hundreds of reviews for the same restaurant, you'd want to know exactly which things people liked and didn't like in their reviews. Fortunately, the Natural Language API has a method that lets you get the sentiment for each entity in the text, called analyzeEntitySentiment

## What we did

In this Lab, we:
1. Learnt how to use the Natural Language API to analyze entities, sentiment, and syntax.
2. Created a Natural Language API request and calling the API with curl
3. Extracted entities and running sentiment analysis on text with the Natural Language API
4. Performed linguistic analysis on text with the Natural Language API
5. Created a Natural Language API request in a different language

## New terms

1. **AnalyzeEntities** : It is a method where the API can extract entities (like people, places, and events) from text.

2. **encodingType**:encodingType tells the API which type of text encoding to use when processing our text. The API will use this to calculate where specific entities appear in our text.

3. **analyzeSyntax**: analyzeSyntax extracts linguistic information, breaking up the given text into a series of sentences and tokens (generally, word boundaries), to provide further analysis on those tokens. For each word in the text, the API tells you the word's part of speech (noun, verb, adjective, etc.) and how it relates to other words in the sentence (Is it the root verb? A modifier?).

